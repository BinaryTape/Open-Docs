# LLM 提供者

Koog 整合了主要的 LLM 提供者，並透過與 [Ollama](https://ollama.com/) 的整合來支援本機模型。
目前支援的提供者如下：

| <div style="width:115px">LLM 提供者</div>                                                                                                                 | 選擇原因                                                                                                                     |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------|
| [OpenAI](https://platform.openai.com/docs/overview) (包含 [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai)) | 具有廣泛功能的進階模型。                                                                                                       |
| [Anthropic](https://www.anthropic.com/)                                                                                                                     | 長上下文和提示快取。                                                                                                           |
| [Google](https://ai.google.dev/)                                                                                                                            | 多模態處理（音訊、視訊）、大型上下文。                                                                                           |
| [DeepSeek](https://www.deepseek.com/)                                                                                                                       | 經濟實惠的推理和程式碼撰寫。                                                                                                   |
| [OpenRouter](https://openrouter.ai/)                                                                                                                        | 一次整合即可存取多個提供者的多個模型，以實現彈性、提供者比較和統一的 API。                                                       |
| [Amazon Bedrock](https://aws.amazon.com/bedrock/)                                                                                                           | AWS 原生環境、企業級安全與合規、多提供者存取。                                                                                 |
| [Mistral](https://mistral.ai/)                                                                                                                              | 歐洲資料託管、符合 GDPR 規範。                                                                                                 |
| [Alibaba](https://www.alibabacloud.com/en?_p_lc=1) ([DashScope](https://dashscope.aliyun.com/) OpenAI 相容用戶端)                                          | 大型上下文和經濟實惠的 Qwen 模型。                                                                                             |
| [Ollama](https://ollama.com/)                                                                                                                               | 隱私保護、本機開發、離線操作，且無需 API 費用。                                                                                  |

下表顯示了 Koog 支援的 LLM 功能，以及哪些提供者在其模型中提供了這些功能。
`*` 符號表示該功能由提供者的特定模型支援。

| <div style="width:115px">LLM 功能</div> | OpenAI                       | Anthropic              | Google                               | DeepSeek | OpenRouter       | Amazon Bedrock   | Mistral                | Alibaba (DashScope OpenAI 相容用戶端) | Ollama (本機模型) |
|-----------------------------------------------|------------------------------|------------------------|--------------------------------------|----------|------------------|------------------|------------------------|-----------------------------------|-----------------------|
| 支援的輸入                                    | 文字、圖像、音訊、文件       | 文字、圖像、文件*      | 文字、圖像、音訊、視訊、文件* | 文字     | 依模型而異       | 依模型而異       | 文字、圖像、文件*      | 文字、圖像、音訊、視訊*          | 文字、圖像*           |
| 回應串流                                      | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                                 | ✓                     |
| 工具                                          | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                                 | ✓                     |
| 工具選擇                                      | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                                 | –                     |
| 結構化輸出 (JSON Schema)                      | ✓                            | –                      | ✓                                    | ✓        | ✓*               | –                | ✓                      | ✓*                                | ✓                     |
| 多重選擇                                      | ✓                            | –                      | ✓                                    | –        | ✓*               | ✓*               | ✓                      | ✓*                                | –                     |
| 溫度                                          | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                                 | ✓                     |
| 推測                                          | ✓*                           | –                      | –                                    | –        | ✓*               | –                | ✓*                     | ✓*                                | –                     |
| 內容審核                                      | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                                 | ✓                     |
| 嵌入                                          | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                                 | ✓                     |
| 提示快取                                      | ✓*                           | ✓                      | –                                    | –        | –                | –                | –                      | –                                 | –                     |
| 補完                                          | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                                 | ✓                     |
| 本機執行                                      | –                            | –                      | –                                    | –        | –                | –                | –                      | –                                 | ✓                     |

!!! note
    Koog 支援建立 AI 代理最常用的功能。
    每個提供者的 LLM 可能還有 Koog 目前不支援的額外功能。
    欲了解更多，請參閱 [模型功能](model-capabilities.md)。

## 使用提供者

Koog 讓您可以在兩個層級上與 LLM 提供者協作：

*   使用 **LLM 用戶端** 與特定提供者直接互動。
    每個用戶端都實現了 `LLMClient` 介面，處理提供者的驗證、請求格式化和回應解析。
    詳情請參閱 [LLM 用戶端](prompts/llm-clients.md)。

*   使用 **提示執行器** 進行更高層次的抽象，它封裝一個或多個 LLM 用戶端，
    管理它們的生命週期，並統一跨提供者的介面。
    它可以選擇在提供者之間切換，並選擇性地回退到已配置的提供者和 LLM，使用其對應的用戶端。
    您可以建立自己的執行器，或使用預定義的特定提供者提示執行器。
    詳情請參閱 [提示執行器](prompts/llm-clients.md)。

提示執行器提供了一個更高層次的抽象層，超越一個或多個 LLM 用戶端。
它管理用戶端生命週期，並提供跨提供者的統一介面。
在多提供者設定中，它可以路由提供者之間的請求，並在核心請求需要時選擇性地回退到指定的用戶端。
您可以建立自己的執行器，或使用預定義的執行器——單一提供者和多提供者選項均可用。

## 後續步驟

-   [建立並執行 AI 代理](getting-started.md) 與特定 LLM 提供者。
-   了解更多關於 [提示](prompts/index.md)。