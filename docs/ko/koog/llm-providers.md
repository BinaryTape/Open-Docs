# LLM 제공업체

Koog는 주요 LLM 제공업체와 연동되며, [Ollama](https://ollama.com/)를 사용하여 로컬 모델도 지원합니다.
다음 제공업체들이 현재 지원됩니다:

| <div style="width:115px">LLM 제공업체</div>                                                                                                                 | 선택 이유                                                                                                                     |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|
| [OpenAI](https://platform.openai.com/docs/overview) ( [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai) 포함) | 광범위한 기능을 갖춘 고급 모델.                                                                                              |
| [Anthropic](https://www.anthropic.com/)                                                                                                                     | 긴 컨텍스트 및 프롬프트 캐싱.                                                                                                |
| [Google](https://ai.google.dev/)                                                                                                                            | 멀티모달 처리(오디오, 비디오), 대규모 컨텍스트.                                                                              |
| [DeepSeek](https://www.deepseek.com/)                                                                                                                       | 비용 효율적인 추론 및 코딩.                                                                                                   |
| [OpenRouter](https://openrouter.ai/)                                                                                                                        | 유연성, 제공업체 비교 및 통합 API를 위해 여러 제공업체의 다양한 모델에 접근할 수 있는 단일 통합. |
| [Amazon Bedrock](https://aws.amazon.com/bedrock/)                                                                                                           | AWS 네이티브 환경, 엔터프라이즈 보안 및 규정 준수, 다중 제공업체 접근.                                                   |
| [Mistral](https://mistral.ai/)                                                                                                                              | 유럽 데이터 호스팅, GDPR 규정 준수.                                                                                           |
| [Alibaba](https://www.alibabacloud.com/en?_p_lc=1) ([DashScope](https://dashscope.aliyun.com/) OpenAI 호환 클라이언트)                                                            | 대규모 컨텍스트 및 비용 효율적인 Qwen 모델.                                                                                   |
| [Ollama](https://ollama.com/)                                                                                                                               | 프라이버시, 로컬 개발, 오프라인 작동 및 API 비용 없음.                                                                       |

아래 표는 Koog가 지원하는 LLM 기능과 해당 기능을 모델에서 제공하는 제공업체를 보여줍니다.
`*` 기호는 해당 기능이 제공업체의 특정 모델에서 지원됨을 의미합니다.

| <div style="width:115px">LLM 기능</div> | OpenAI                       | Anthropic              | Google                               | DeepSeek | OpenRouter       | Amazon Bedrock   | Mistral                | Alibaba (DashScope OpenAI 호환 클라이언트)       | Ollama (로컬 모델) |
|:----------------------------------------|:-----------------------------|:-----------------------|:-------------------------------------|:---------|:-----------------|:-----------------|:-----------------------|:---------------------------|:----------------------|
| 지원되는 입력                           | 텍스트, 이미지, 오디오, 문서 | 텍스트, 이미지, 문서* | 텍스트, 이미지, 오디오, 비디오, 문서* | 텍스트     | 모델에 따라 다름 | 모델에 따라 다름 | 텍스트, 이미지, 문서* | 텍스트, 이미지, 오디오, 비디오* | 텍스트, 이미지*          |
| 응답 스트리밍                           | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 도구                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | ✓                     |
| 도구 선택                               | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | –                     |
| 구조화된 출력 (JSON 스키마)             | ✓                            | –                      | ✓                                    | ✓        | ✓*               | –                | ✓                      | ✓*                         | ✓                     |
| 다중 선택                               | ✓                            | –                      | ✓                                    | –        | ✓*               | ✓*               | ✓                      | ✓*                         | –                     |
| 온도                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 추측                                    | ✓*                           | –                      | –                                    | –        | ✓*               | –                | ✓*                     | ✓*                         | –                     |
| 콘텐츠 조정                             | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| 임베딩                                  | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| 프롬프트 캐싱                           | ✓*                           | ✓                      | –                                    | –        | –                | –                | –                      | –                          | –                     |
| 완성                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 로컬 실행                               | –                            | –                      | –                                    | –        | –                | –                | –                      | –                          | ✓                     |

!!! note
    Koog는 AI 에이전트를 생성하는 데 가장 일반적으로 사용되는 기능을 지원합니다.
    각 제공업체의 LLM은 Koog가 현재 지원하지 않는 추가 기능을 가질 수 있습니다.
    자세한 내용은 [모델 기능](model-capabilities.md)을 참조하세요.

## 제공업체 연동

Koog는 두 가지 수준에서 LLM 제공업체와 연동할 수 있도록 합니다:

*   특정 제공업체와 직접 상호 작용하기 위해 **LLM 클라이언트**를 사용합니다.
    각 클라이언트는 `LLMClient` 인터페이스를 구현하며, 제공업체에 대한 인증,
    요청 형식 지정 및 응답 구문 분석을 처리합니다.
    자세한 내용은 [LLM 클라이언트](prompts/llm-clients.md)를 참조하세요.

    *   하나 이상의 LLM 클라이언트를 래핑하고,
        수명 주기를 관리하며, 제공업체 전반에 걸쳐 인터페이스를 통합하는 고수준 추상화를 위해 **프롬프트 실행기**를 사용합니다.
        이는 제공업체 간 전환을 처리하고
        필요에 따라 해당 클라이언트를 사용하는 구성된 제공업체 및 LLM으로 선택적으로 폴백할 수 있습니다.
        자신만의 실행기를 생성하거나 특정 제공업체에 대해 미리 정의된 프롬프트 실행기를 사용할 수 있습니다.
        자세한 내용은 [프롬프트 실행기](prompts/llm-clients.md)를 참조하세요.

프롬프트 실행기는 하나 이상의 `LLMClient` 위에 고수준 계층을 제공합니다. 이는 클라이언트 수명 주기를 관리하고 제공업체 전반에 걸쳐 통합된 인터페이스를 노출합니다. 다중 제공업체 설정에서, 이는 제공업체 간에 요청을 라우팅하고, 핵심 요청에 필요할 경우 지정된 클라이언트로 선택적으로 폴백할 수 있습니다. 자신만의 실행기를 생성하거나 미리 정의된 실행기를 사용할 수 있으며, 단일 제공업체 및 다중 제공업체 옵션 모두 사용 가능합니다.

## 다음 단계

-   특정 LLM 제공업체로 [에이전트 생성 및 실행](getting-started.md).
-   [프롬프트](prompts/index.md)에 대해 자세히 알아보세요.