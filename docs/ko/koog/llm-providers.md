# LLM 제공업체

Koog는 주요 LLM 제공업체와 연동되며, [Ollama](https://ollama.com/)를 사용하여 로컬 모델도 지원합니다.
다음 제공업체들이 현재 지원됩니다:

| <div style="width:115px">LLM 제공업체</div>                                                                                                                 | 선택 이유                                                                                                                     |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|
| [OpenAI](https://platform.openai.com/docs/overview) ( [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai) 포함) | 광범위한 기능을 갖춘 고급 모델.                                                                                              |
| [Anthropic](https://www.anthropic.com/)                                                                                                                     | 긴 컨텍스트 및 프롬프트 캐싱.                                                                                                |
| [Google](https://ai.google.dev/)                                                                                                                            | 멀티모달 처리(오디오, 비디오), 대규모 컨텍스트.                                                                              |
| [DeepSeek](https://www.deepseek.com/)                                                                                                                       | 비용 효율적인 추론 및 코딩.                                                                                                   |
| [OpenRouter](https://openrouter.ai/)                                                                                                                        | 유연성, 제공업체 비교 및 통합 API를 위해 여러 제공업체의 다양한 모델에 접근할 수 있는 단일 통합. |
| [Amazon Bedrock](https://aws.amazon.com/bedrock/)                                                                                                           | AWS 네이티브 환경, 엔터프라이즈 보안 및 규정 준수, 다중 제공업체 접근.                                                   |
| [Mistral](https://mistral.ai/)                                                                                                                              | 유럽 데이터 호스팅, GDPR 규정 준수.                                                                                           |
| [Alibaba](https://www.alibabacloud.com/en?_p_lc=1) ([DashScope](https://dashscope.aliyun.com/))                                                             | 대규모 컨텍스트 및 비용 효율적인 Qwen 모델.                                                                                   |
| [Ollama](https://ollama.com/)                                                                                                                               | 프라이버시, 로컬 개발, 오프라인 작동 및 API 비용 없음.                                                                       |

아래 표는 Koog가 지원하는 LLM 기능과 해당 기능을 모델에서 제공하는 제공업체를 보여줍니다.
`*` 기호는 해당 기능이 제공업체의 특정 모델에서 지원됨을 의미합니다.

| <div style="width:115px">LLM 기능</div> | OpenAI                       | Anthropic              | Google                               | DeepSeek | OpenRouter       | Amazon Bedrock   | Mistral                | Alibaba (DashScope)        | Ollama (로컬 모델) |
|:----------------------------------------|:-----------------------------|:-----------------------|:-------------------------------------|:---------|:-----------------|:-----------------|:-----------------------|:---------------------------|:----------------------|
| 지원되는 입력                           | 텍스트, 이미지, 오디오, 문서 | 텍스트, 이미지, 문서* | 텍스트, 이미지, 오디오, 비디오, 문서* | 텍스트     | 모델에 따라 다름 | 모델에 따라 다름 | 텍스트, 이미지, 문서* | 텍스트, 이미지, 오디오, 비디오* | 텍스트, 이미지*          |
| 응답 스트리밍                           | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 도구                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | ✓                     |
| 도구 선택                               | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | –                     |
| 구조화된 출력 (JSON 스키마)             | ✓                            | –                      | ✓                                    | ✓        | ✓*               | –                | ✓                      | ✓*                         | ✓                     |
| 다중 선택                               | ✓                            | –                      | ✓                                    | –        | ✓*               | ✓*               | ✓                      | ✓*                         | –                     |
| 온도                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 추측                                    | ✓*                           | –                      | –                                    | –        | ✓*               | –                | ✓*                     | ✓*                         | –                     |
| 콘텐츠 조정                             | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| 임베딩                                  | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| 프롬프트 캐싱                           | ✓*                           | ✓                      | –                                    | –        | –                | –                | –                      | –                          | –                     |
| 완성                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 로컬 실행                               | –                            | –                      | –                                    | –        | –                | –                | –                      | –                          | ✓                     |

!!! note
    Koog는 AI 에이전트를 생성하는 데 가장 일반적으로 사용되는 기능을 지원합니다.
    각 제공업체의 LLM은 Koog가 현재 지원하지 않는 추가 기능을 가질 수 있습니다.
    자세한 내용은 [모델 기능](model-capabilities.md)을 참조하세요.

## 제공업체 연동

Koog는 두 가지 수준에서 LLM 제공업체와 연동할 수 있도록 합니다:

*   **LLM 클라이언트**를 사용하여 특정 제공업체와 직접 상호 작용.
    각 클라이언트는 `LLMClient` 인터페이스를 구현하며, 제공업체에 대한 인증,
    요청 형식 지정 및 응답 구문 분석을 처리합니다.
    자세한 내용은 [LLM 클라이언트로 프롬프트 실행](prompt-api.md#running-prompts-with-llm-clients)을 참조하세요.

*   고수준 추상화를 위한 **프롬프트 실행기** 사용. 이 실행기는 하나 또는 여러 LLM 클라이언트를 래핑하고,
    수명 주기를 관리하며, 제공업체 전반에 걸쳐 인터페이스를 통합합니다.
    특정 제공업체를 사용할 수 없는 경우 선택적으로 단일 LLM 클라이언트로 폴백할 수 있습니다.
    프롬프트 실행기는 또한 실패, 재시도 및 제공업체 간 전환을 처리합니다.
    자신만의 실행기를 생성하거나 특정 제공업체에 대해 미리 정의된 프롬프트 실행기를 사용할 수 있습니다.
    자세한 내용은 [프롬프트 실행기로 프롬프트 실행](prompt-api.md#running-prompts-with-prompt-executors)을 참조하세요.

## 다음 단계

-   특정 LLM 제공업체로 [에이전트 생성 및 실행](getting-started.md).
-   [프롬프트](prompt-api.md) 및 [LLM 클라이언트와 프롬프트 실행기 중 선택하는 방법](prompt-api.md#choosing-between-llm-clients-and-prompt-executors)에 대해 자세히 알아보세요.