import{_ as d,c as i,o as s,ag as a}from"./chunks/framework.Bksy39di.js";const c=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"koog/model-capabilities.md","filePath":"koog/model-capabilities.md","lastUpdated":1755146406000}'),l={name:"koog/model-capabilities.md"};function e(h,t,n,p,o,r){return s(),i("div",null,t[0]||(t[0]=[a(`<p>Koog 提供了一套抽象和实现，用于以与提供商无关的方式处理来自各种 LLM 提供商的大型语言模型 (LLM)。其中包括以下类：</p><ul><li><p><strong>LLMCapability</strong>：一个类层次结构，定义了 LLM 可支持的各种能力，例如：</p><ul><li>用于控制响应随机性的温度调整</li><li>用于外部系统交互的工具集成</li><li>用于处理视觉数据的视觉处理</li><li>用于向量表示的嵌入生成</li><li>用于文本生成任务的补全</li><li>用于结构化数据的 Schema 支持（带 Simple 和 Full 变体的 JSON）</li><li>用于探索性响应的推测</li></ul></li><li><p><strong>LLModel</strong>：一个数据类，表示具有其提供商、唯一标识符和支持能力的特定 LLM。</p></li></ul><p>这为以统一方式与不同 LLM 提供商进行交互奠定了基础，允许应用程序处理各种模型，同时抽象出提供商特有的细节。</p><h2 id="llm-能力" tabindex="-1">LLM 能力 <a class="header-anchor" href="#llm-能力" aria-label="Permalink to &quot;LLM 能力&quot;">​</a></h2><p>LLM 能力表示大型语言模型可以支持的特定特性或功能。在 Koog 框架中，能力用于定义特定模型可以做什么以及如何配置它。每种能力都表示为 <code>LLMCapability</code> 类的子类或数据对象。</p><p>在您的应用程序中配置 LLM 以供使用时，您通过在创建 <code>LLModel</code> 实例时将它们添加到 <code>capabilities</code> list 中来指定它支持哪些能力。这允许框架正确地与模型交互并适当地使用其特性。</p><h3 id="核心能力" tabindex="-1">核心能力 <a class="header-anchor" href="#核心能力" aria-label="Permalink to &quot;核心能力&quot;">​</a></h3><p>下面的 list 包含了 Koog 框架中模型可用的核心 LLM 特有的能力：</p><ul><li><p><strong>推测</strong> (<code>LLMCapability.Speculation</code>)：让模型生成具有不同可能性程度的推测性或探索性响应。适用于需要更广泛潜在结果的创造性或假设场景。</p></li><li><p><strong>温度</strong> (<code>LLMCapability.Temperature</code>)：允许调整模型的响应随机性或创造力水平。较高的温度值会产生更多样化的输出，而较低的值会导致更专注和确定性的响应。</p></li><li><p><strong>工具</strong> (<code>LLMCapability.Tools</code>)：表示支持外部工具使用或集成。此能力让模型运行特定工具或与外部系统交互。</p></li><li><p><strong>工具选择</strong> (<code>LLMCapability.ToolChoice</code>)：配置工具调用如何与 LLM 协同工作。根据模型，它可以配置为：</p><ul><li>自动选择生成文本或工具调用</li><li>仅生成工具调用，从不生成文本</li><li>仅生成文本，从不生成工具调用</li><li>强制调用已定义工具中的特定工具</li></ul></li><li><p><strong>多项选择</strong> (<code>LLMCapability.MultipleChoices</code>)：让模型为单个提示生成多个独立的回复选择。</p></li></ul><h3 id="媒体处理能力" tabindex="-1">媒体处理能力 <a class="header-anchor" href="#媒体处理能力" aria-label="Permalink to &quot;媒体处理能力&quot;">​</a></h3><p>以下 list 表示用于处理图像或音频等媒体内容的一组能力：</p><ul><li><p><strong>视觉</strong> (<code>LLMCapability.Vision</code>)：一个用于基于视觉的能力的类，可处理、分析和推断视觉数据中的洞察。 支持以下类型的视觉数据：</p><ul><li><strong>图像</strong> (<code>LLMCapability.Vision.Image</code>)：处理图像相关的视觉任务，例如图像分析、识别和解释。</li><li><strong>视频</strong> (<code>LLMCapability.Vision.Video</code>)：处理视频数据，包括分析和理解视频内容。</li></ul></li><li><p><strong>音频</strong> (<code>LLMCapability.Audio</code>)：提供与音频相关的功能，例如转录、音频生成或基于音频的交互。</p></li><li><p><strong>文档</strong> (<code>LLMCapability.Document</code>)：启用对基于文档的输入和输出的处理。</p></li></ul><h3 id="文本处理能力" tabindex="-1">文本处理能力 <a class="header-anchor" href="#文本处理能力" aria-label="Permalink to &quot;文本处理能力&quot;">​</a></h3><p>以下能力 list 表示文本生成和处理功能：</p><ul><li><p><strong>嵌入</strong> (<code>LLMCapability.Embed</code>)：让模型从输入文本生成向量嵌入，从而实现相似度比较、聚类及其他基于向量的分析。</p></li><li><p><strong>补全</strong> (<code>LLMCapability.Completion</code>)：包括根据给定输入上下文生成文本或内容，例如补全句子、生成建议或生成与输入数据一致的内容。</p></li><li><p><strong>提示缓存</strong> (<code>LLMCapability.PromptCaching</code>)：支持提示的缓存功能，潜在地提高重复或相似查询的性能。</p></li><li><p><strong>内容审核</strong> (<code>LLMCapability.Moderation</code>)：让模型分析文本中潜在有害内容，并根据骚扰、仇恨言论、自残、色情内容、暴力等各种类别进行分类。</p></li></ul><h3 id="schema-能力" tabindex="-1">Schema 能力 <a class="header-anchor" href="#schema-能力" aria-label="Permalink to &quot;Schema 能力&quot;">​</a></h3><p>下面的 list 指示与处理结构化数据相关的能力：</p><ul><li><strong>Schema</strong> (<code>LLMCapability.Schema</code>)：一个用于结构化 Schema 能力的类，与使用特定格式进行数据交互和编码相关。 包括对以下格式的支持： <ul><li><strong>JSON</strong> (<code>LLMCapability.Schema.JSON</code>)：JSON Schema 支持，具有不同级别： <ul><li><strong>基础</strong> (<code>LLMCapability.Schema.JSON.Basic</code>)：提供轻量级或基础的 JSON 处理能力。</li><li><strong>标准</strong> (<code>LLMCapability.Schema.JSON.Standard</code>)：提供全面的 JSON Schema 支持，适用于复杂数据结构。</li></ul></li></ul></li></ul><h2 id="创建模型-llmodel-配置" tabindex="-1">创建模型 (LLModel) 配置 <a class="header-anchor" href="#创建模型-llmodel-配置" aria-label="Permalink to &quot;创建模型 (LLModel) 配置&quot;">​</a></h2><p>为了以通用、与提供商无关的方式定义模型，请创建 <code>LLModel</code> 类实例作为模型配置，并使用以下参数：</p><table tabindex="0"><thead><tr><th>名称</th><th>数据类型</th><th>必需</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td><code>provider</code></td><td>LLMProvider</td><td>Yes</td><td></td><td>LLM 提供商，例如 Google 或 OpenAI。这标识了创建或托管模型的公司或组织。</td></tr><tr><td><code>id</code></td><td>String</td><td>Yes</td><td></td><td>LLM 实例的唯一标识符。这通常表示特定的模型版本或名称。例如，<code>gpt-4-turbo</code>、<code>claude-3-opus</code>、<code>llama-3-2</code>。</td></tr><tr><td><code>capabilities</code></td><td>List&lt;LLMCapability&gt;</td><td>Yes</td><td></td><td>LLM 支持的能力 list，例如温度调整、工具使用或基于 Schema 的任务。这些能力定义了模型可以做什么以及如何配置它。</td></tr><tr><td><code>contextLength</code></td><td>Long</td><td>Yes</td><td></td><td>LLM 的上下文长度。这是 LLM 可处理的最大 token 数量。</td></tr><tr><td><code>maxOutputTokens</code></td><td>Long</td><td>No</td><td><code>null</code></td><td>提供商可为 LLM 生成的最大 token 数量。</td></tr></tbody></table><h3 id="示例" tabindex="-1">示例 <a class="header-anchor" href="#示例" aria-label="Permalink to &quot;示例&quot;">​</a></h3><p>本节提供了使用不同能力创建 <code>LLModel</code> 实例的详细示例。</p><p>以下代码表示具有核心能力的基础 LLM 配置：</p><div class="language-kotlin vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">kotlin</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> basicModel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LLModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    provider </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LLMProvider.OpenAI,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    id </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt-4-turbo&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    capabilities </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> listOf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Temperature,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Tools,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Schema.JSON.Standard</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    contextLength </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 128_000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>以下模型配置是一个具有视觉能力的多模态 LLM：</p><div class="language-kotlin vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">kotlin</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> visionModel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LLModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    provider </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LLMProvider.OpenAI,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    id </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt-4-vision&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    capabilities </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> listOf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Temperature,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Vision.Image,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.MultipleChoices</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    contextLength </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1_047_576</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    maxOutputTokens </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 32_768</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>一个具有音频处理能力的 LLM：</p><div class="language-kotlin vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">kotlin</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> audioModel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LLModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    provider </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LLMProvider.Anthropic,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    id </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;claude-3-opus&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    capabilities </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> listOf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Audio,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.Temperature,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLMCapability.PromptCaching</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    contextLength </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 200_000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>除了创建 <code>LLModel</code> 实例并指定所有相关参数之外，Koog 还包含一个预定义模型及其配置（包含支持的能力）的集合。 要使用预定义的 Ollama 模型，请按如下方式指定：</p><div class="language-kotlin vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">kotlin</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> metaModel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OllamaModels.Meta.LLAMA_3_2</span></span></code></pre></div><p>要检测模型是否支持特定能力，请使用 <code>contains</code> 方法检测 <code>capabilities</code> list 中是否存在该能力：</p><div class="language-kotlin vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">kotlin</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Check if models support specific capabilities</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> supportsTools </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> basicModel.capabilities.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">contains</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(LLMCapability.Tools) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// true</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> supportsVideo </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> visionModel.capabilities.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">contains</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(LLMCapability.Vision.Video) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// false</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Check for schema capabilities</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jsonCapability </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> basicModel.capabilities.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">filterIsInstance</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">LLMCapability</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Schema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">JSON</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;().</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">firstOrNull</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">val</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> hasFullJsonSupport </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jsonCapability </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LLMCapability.Schema.JSON.Standard </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// true</span></span></code></pre></div><h3 id="按模型划分的-llm-能力" tabindex="-1">按模型划分的 LLM 能力 <a class="header-anchor" href="#按模型划分的-llm-能力" aria-label="Permalink to &quot;按模型划分的 LLM 能力&quot;">​</a></h3><p>此参考显示了不同提供商的每个模型支持哪些 LLM 能力。</p><p>在下表中：</p><ul><li><code>✓</code> 表示模型支持该能力</li><li><code>-</code> 表示模型不支持该能力</li><li>对于 JSON Schema，<code>Full</code> 或 <code>Simple</code> 表示模型支持哪种 JSON Schema 能力变体</li></ul><h4 id="google-models" tabindex="-1">Google models <a class="header-anchor" href="#google-models" aria-label="Permalink to &quot;Google models&quot;">​</a></h4><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Completion</th><th>Multiple Choices</th><th>Tools</th><th>Tool Choice</th><th>视觉 (图像)</th><th>视觉 (视频)</th><th>Audio</th></tr></thead><tbody><tr><td>Gemini2_5Pro</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini2_5Flash</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini2_0Flash</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini2_0Flash001</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini2_0FlashLite</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini2_0FlashLite001</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Pro</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5ProLatest</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Pro002</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Flash</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5FlashLatest</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Flash002</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Flash8B</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Flash8B001</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini1_5Flash8BLatest</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>✓</td><td>✓</td></tr></tbody></table><h4 id="openai-models" tabindex="-1">OpenAI models <a class="header-anchor" href="#openai-models" aria-label="Permalink to &quot;OpenAI models&quot;">​</a></h4><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Completion</th><th>Multiple Choices</th><th>Tools</th><th>Tool Choice</th><th>视觉 (图像)</th><th>视觉 (视频)</th><th>Audio</th><th>推测</th><th>内容审核</th></tr></thead><tbody><tr><td>Reasoning.GPT4oMini</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Reasoning.O3Mini</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Reasoning.O1Mini</td><td>-</td><td>Full</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Reasoning.O3</td><td>-</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Reasoning.O1</td><td>-</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Chat.GPT4o</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Chat.GPT4_1</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td></tr><tr><td>Audio.GPT4oMiniAudio</td><td>✓</td><td>-</td><td>✓</td><td>-</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>Audio.GPT4oAudio</td><td>✓</td><td>-</td><td>✓</td><td>-</td><td>✓</td><td>✓</td><td>-</td><td>-</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>Moderation.Omni</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>✓</td><td>-</td><td>-</td><td>-</td><td>✓</td></tr><tr><td>Moderation.Text</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>✓</td></tr></tbody></table><h4 id="anthropic-models" tabindex="-1">Anthropic models <a class="header-anchor" href="#anthropic-models" aria-label="Permalink to &quot;Anthropic models&quot;">​</a></h4><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Completion</th><th>Tools</th><th>Tool Choice</th><th>视觉 (图像)</th></tr></thead><tbody><tr><td>Opus_4</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Sonnet_4</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Sonnet_3_7</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Haiku_3_5</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Sonnet_3_5</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Haiku_3</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Opus_3</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr></tbody></table><h4 id="ollama-models" tabindex="-1">Ollama models <a class="header-anchor" href="#ollama-models" aria-label="Permalink to &quot;Ollama models&quot;">​</a></h4><h5 id="meta-models" tabindex="-1">Meta models <a class="header-anchor" href="#meta-models" aria-label="Permalink to &quot;Meta models&quot;">​</a></h5><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Tools</th><th>内容审核</th></tr></thead><tbody><tr><td>LLAMA_3_2_3B</td><td>✓</td><td>Simple</td><td>✓</td><td>-</td></tr><tr><td>LLAMA_3_2</td><td>✓</td><td>Simple</td><td>✓</td><td>-</td></tr><tr><td>LLAMA_4</td><td>✓</td><td>Simple</td><td>✓</td><td>-</td></tr><tr><td>LLAMA_GUARD_3</td><td>-</td><td>-</td><td>-</td><td>✓</td></tr></tbody></table><h5 id="alibaba-models" tabindex="-1">Alibaba models <a class="header-anchor" href="#alibaba-models" aria-label="Permalink to &quot;Alibaba models&quot;">​</a></h5><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Tools</th></tr></thead><tbody><tr><td>QWEN_2_5_05B</td><td>✓</td><td>Simple</td><td>✓</td></tr><tr><td>QWEN_3_06B</td><td>✓</td><td>Simple</td><td>✓</td></tr><tr><td>QWQ</td><td>✓</td><td>Simple</td><td>✓</td></tr><tr><td>QWEN_CODER_2_5_32B</td><td>✓</td><td>Simple</td><td>✓</td></tr></tbody></table><h5 id="groq-models" tabindex="-1">Groq models <a class="header-anchor" href="#groq-models" aria-label="Permalink to &quot;Groq models&quot;">​</a></h5><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Tools</th></tr></thead><tbody><tr><td>LLAMA_3_GROK_TOOL_USE_8B</td><td>✓</td><td>Full</td><td>✓</td></tr><tr><td>LLAMA_3_GROK_TOOL_USE_70B</td><td>✓</td><td>Full</td><td>✓</td></tr></tbody></table><h5 id="granite-models" tabindex="-1">Granite models <a class="header-anchor" href="#granite-models" aria-label="Permalink to &quot;Granite models&quot;">​</a></h5><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Tools</th><th>视觉 (图像)</th></tr></thead><tbody><tr><td>GRANITE_3_2_VISION</td><td>✓</td><td>Simple</td><td>✓</td><td>✓</td></tr></tbody></table><h4 id="openrouter-models" tabindex="-1">OpenRouter models <a class="header-anchor" href="#openrouter-models" aria-label="Permalink to &quot;OpenRouter models&quot;">​</a></h4><table tabindex="0"><thead><tr><th>Model</th><th>Temperature</th><th>JSON Schema</th><th>Completion</th><th>推测</th><th>Tools</th><th>Tool Choice</th><th>视觉 (图像)</th></tr></thead><tbody><tr><td>Phi4Reasoning</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Claude3Opus</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Claude3Sonnet</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Claude3Haiku</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>GPT4</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>GPT4o</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>GPT4Turbo</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>GPT35Turbo</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Gemini15Pro</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Gemini15Flash</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Llama3</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Llama3Instruct</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Mistral7B</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Mixtral8x7B</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Claude3VisionSonnet</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Claude3VisionOpus</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Claude3VisionHaiku</td><td>✓</td><td>Full</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr></tbody></table>`,54)]))}const E=d(l,[["render",e]]);export{c as __pageData,E as default};
