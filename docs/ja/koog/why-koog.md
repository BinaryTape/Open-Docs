# Koogを選ぶ理由

Koogは、JetBrainsレベルの品質で現実世界の問題を解決するために設計されています。高度なAIアルゴリズム、すぐに利用できる実績ある手法、Kotlin DSL、そして従来のフレームワークを超える堅牢なマルチプラットフォームサポートを提供します。

## JVMおよびKotlinアプリケーションとの統合

Koogは、JVMおよびKotlin開発者向けに特別に設計されたKotlinドメイン固有言語（DSL）を提供します。これにより、KotlinおよびJavaベースのアプリケーションへのスムーズな統合が保証され、生産性が大幅に向上し、全体的な開発者エクスペリエンスが強化されます。

## JetBrains製品による実世界での検証

Koogは、社内AIエージェントを含む複数のJetBrains製品を支えています。この実世界での統合により、Koogは実際のユースケースに対して継続的にテスト、改良、検証されています。Koogは実用的なものに焦点を当て、広範なフィードバックと実際の製品シナリオからの洞察を取り入れています。この統合により、Koogは他のフレームワークから際立つ強みを持っています。

## すぐに利用できる高度なソリューション

Koogには、エージェントシステム開発の簡素化と高速化を実現する事前構築済みで構成可能なソリューションが含まれており、基本的なコンポーネントのみを提供するフレームワークとは一線を画しています。

*   **複数の履歴圧縮戦略。** Koogは、すぐに利用できる高度な戦略を備えており、長期間にわたる会話を圧縮・管理し、手動でのアプローチの試行錯誤が不要になります。MLエンジニアによってテストおよび改良された、調整済みのプロンプト、手法、アルゴリズムにより、実績のある方法でパフォーマンスを向上させることができます。圧縮戦略の詳細については、[履歴圧縮](https://docs.koog.ai/history-compression/)を参照してください。Koogが実世界のシナリオで圧縮とコンテキスト管理をどのように処理するかについては、[この記事](https://blog.jetbrains.com/ai/2025/07/when-tool-calling-becomes-an-addiction-debugging-llm-patterns-in-koog/)をご覧ください。
*   **シームレスなLLM切り替え。** 既存の会話履歴を失うことなく、いつでも会話を異なる大規模言語モデル（LLM）と新しい利用可能なツールセットに切り替えることができます。Koogは履歴を自動的に書き換え、利用できないツールを処理するため、スムーズな移行と自然な対話フローが可能になります。プライマリモデルが利用できない状況に対処するためにフォールバックモデルを設定でき、中断のない実行を保証します。この柔軟性により、A/Bテストや、異なるタスク向けに特化したモデルの利用が可能になります。
*   **高度な永続化。** Koogでは、チャットメッセージだけでなく、完全なエージェントステートマシンを復元できます。これにより、チェックポイント、障害回復、さらにはステートマシンの実行中の任意の時点にロールバックする機能が実現します。
*   **堅牢なリトライコンポーネント。** Koogにはリトライメカニズムが組み込まれており、エージェントシステム内の任意の操作セットをラップし、設定可能な条件を満たすまで再試行できます。フィードバックを提供し、各試行を調整して、信頼性の高い結果を保証できます。LLM呼び出しがタイムアウトしたり、ツールが期待どおりに機能しなかったり、ネットワークの問題が発生したりした場合でも、Koogは一時的な障害時でもエージェントが回復力と効果的なパフォーマンスを維持できるようにします。より詳細な技術情報については、[リトライ機能](https://docs.koog.ai/history-compression/)を参照してください。
*   **Markdown DSLによる構造化された型付きストリーミング。** KoogはLLMの出力をストリーミングし、Markdown DSLを使用して構造化された型付きイベントに解析します。ヘッダー、箇条書き、正規表現パターンなどの特定の要素のハンドラーを登録し、関連する部分のみをリアルタイムで受け取ることができます。このアプローチは、Markdownによる人間が読めるフィードバックと、構造化された型付けによる機械が解析できるデータを提供し、透過性の欠如を効果的に解消し、ユーザーエクスペリエンスを向上させます。これにより、予測可能な出力と、プログレッシブなコンテンツレンダリングを備えた動的なユーザーインターフェースが保証されます。

## 幅広い統合、マルチプラットフォームサポート、強化された可観測性

Koogは、さまざまなプラットフォームと環境でのエージェントアプリケーションの開発とデプロイをサポートします。

*   **マルチプラットフォームサポート。** JVM、JS、WasmJS、およびiOSターゲットにわたってエージェントアプリケーションをデプロイできます。
*   **幅広いAI統合。** Koogは、OpenAIやAnthropicなどの主要なLLMプロバイダー、およびBedrockのようなエンタープライズレベルのAIクラウドと統合します。Ollamaなどのローカルモデルもサポートしています。利用可能なプロバイダーの完全なリストについては、[利用可能なLLMプロバイダーとプラットフォーム](https://docs.koog.ai/#available-llm-providers-and-platforms)を参照してください。
*   **OpenTelemetryサポート。** Koogは、AIアプリケーションの監視とデバッグのために、[W&B Weave](https://wandb.ai/site/weave/)や[Langfuse](https://langfuse.com/)などの一般的な可観測性プロバイダーとのすぐに利用できる統合を提供します。ネイティブのOpenTelemetryサポートにより、システムで既に使用しているツールと同じツールを使用してエージェントをトレース、ログ記録、および測定できます。詳細については、[OpenTelemetry](https://docs.koog.ai/opentelemetry-support/)を参照してください。
*   **Spring BootおよびKtorとの統合。** Koogは、広く使用されているエンタープライズ環境と統合します。
    *   Ktorサーバーを使用している場合、Koogをプラグインとしてインストールし、設定ファイルを使用してプロバイダーを設定し、LLMクライアントを手動で接続することなく、任意のルートから直接エージェントを呼び出すことができます。
    *   Spring Bootの場合、Koogはすぐに使えるBeanと自動設定されたLLMクライアントを提供し、AIを活用したワークフローの構築を容易にします。

## MLエンジニアおよびプロダクトチームとのコラボレーション

Koogのユニークな利点は、JetBrainsのMLエンジニアおよびプロダクトチームとの直接的なコラボレーションです。これにより、Koogで構築された機能が単なる理論ではなく、実際の製品要件に基づいてテストおよび改良されていることが保証されます。これは、Koogが以下を組み込んでいることを意味します。

*   実世界のパフォーマンス向けに最適化された**微調整されたプロンプトと戦略**。
*   製品開発を通じて発見・検証された**実績のあるエンジニアリングアプローチ**（独自の履歴圧縮戦略など）。詳細については、[こちらの記事](https://blog.jetbrains.com/ai/2025/07/when-tool-calling-becomes-an-addiction-debugging-llm-patterns-in-koog/)をご覧ください。
*   Koogが効率的であり続け、進化するニーズに適応できるようにする**継続的な改善**。

## 開発者コミュニティへのコミットメント

Koogチームは、強力な開発者コミュニティの構築に深くコミットしています。フィードバックを積極的に収集し取り入れることで、Koogは開発者のニーズを効果的に満たすように進化します。私たちは、開発者を力づけるために、多様なAIアーキテクチャ、包括的なベンチマーク、詳細なユースケースガイド、および教育リソースのサポートを積極的に拡大しています。

## 始めるには

*   [概要](https://docs.koog.ai/)でKoogの機能を探る。
*   [はじめに](https://docs.koog.ai/single-run-agents/)ガイドを使用して、最初のKoogエージェントを構築する。
*   Koogの[リリースノート](https://github.com/JetBrains/koog/blob/main/CHANGELOG.md)で最新の更新を確認する。
*   [例](https://docs.koog.ai/examples/)から学ぶ。