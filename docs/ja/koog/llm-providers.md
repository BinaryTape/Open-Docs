# LLMプロバイダー

Koogは主要なLLMプロバイダーと連携し、[Ollama](https://ollama.com/)を使用してローカルモデルもサポートしています。
現在、以下のプロバイダーがサポートされています。

| <div style="width:115px">LLMプロバイダー</div>                                                                                                                 | 選択する理由                                                                                                                     |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------|
| [OpenAI](https://platform.openai.com/docs/overview) ( [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai)を含む) | 幅広い機能を備えた高度なモデル。                                                                             |
| [Anthropic](https://www.anthropic.com/)                                                                                                                     | 長いコンテキストとプロンプトキャッシング。                                                                                              |
| [Google](https://ai.google.dev/)                                                                                                                            | マルチモーダル処理（音声、動画）、大規模なコンテキスト。                                                                          |
| [DeepSeek](https://www.deepseek.com/)                                                                                                                       | 費用対効果の高い推論とコーディング。                                                                                           |
| [OpenRouter](https://openrouter.ai/)                                                                                                                        | 複数のプロバイダーの複数モデルへ一元的にアクセスでき、柔軟性、プロバイダー間の比較、統一されたAPIを提供。 |
| [Amazon Bedrock](https://aws.amazon.com/bedrock/)                                                                                                           | AWSネイティブ環境、エンタープライズセキュリティとコンプライアンス、マルチプロバイダーアクセス。                                             |
| [Mistral](https://mistral.ai/)                                                                                                                              | 欧州でのデータホスティング、GDPR準拠。                                                                                        |
| [Alibaba](https://www.alibabacloud.com/en?_p_lc=1) ([DashScope](https://dashscope.aliyuncs.com/))                                                             | 大規模なコンテキストと費用対効果の高いQwenモデル。                                                                                 |
| [Ollama](https://ollama.com/)                                                                                                                               | プライバシー、ローカル開発、オフライン運用、APIコストなし。                                                               |

以下の表は、KoogがサポートするLLM機能と、これらの機能がどのプロバイダーのモデルで提供されているかを示しています。
`*`記号は、その機能がプロバイダーの特定のモデルでサポートされていることを意味します。

| <div style="width:115px">LLM機能</div> | OpenAI                       | Anthropic              | Google                               | DeepSeek | OpenRouter       | Amazon Bedrock   | Mistral                | Alibaba (DashScope)        | Ollama (ローカルモデル) |
|:--------------------------------------|:-----------------------------|:-----------------------|:-------------------------------------|:---------|:-----------------|:-----------------|:-----------------------|:---------------------------|:----------------------|
| サポートされる入力                               | テキスト、画像、音声、ドキュメント | テキスト、画像、ドキュメント* | テキスト、画像、音声、動画、ドキュメント* | テキスト     | モデルによる | モデルによる | テキスト、画像、ドキュメント* | テキスト、画像、音声、動画* | テキスト、画像*          |
| レスポンスストリーミング                            | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| ツール                                         | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | ✓                     |
| ツール選択                                   | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓*               | ✓                      | ✓                          | –                     |
| 構造化出力 (JSON Schema)               | ✓                            | –                      | ✓                                    | ✓        | ✓*               | –                | ✓                      | ✓*                         | ✓                     |
| 複数選択                              | ✓                            | –                      | ✓                                    | –        | ✓*               | ✓*               | ✓                      | ✓*                         | –                     |
| Temperature                                   | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| 投機的サンプリング                                   | ✓*                           | –                      | –                                    | –        | ✓*               | –                | ✓*                     | ✓*                         | –                     |
| コンテンツモデレーション                            | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| 埋め込み                                    | ✓                            | –                      | –                                    | –        | –                | ✓                | ✓                      | –                          | ✓                     |
| プロンプトキャッシング                                | ✓*                           | ✓                      | –                                    | –        | –                | –                | –                      | –                          | –                     |
| 完了                                    | ✓                            | ✓                      | ✓                                    | ✓        | ✓                | ✓                | ✓                      | ✓                          | ✓                     |
| ローカル実行                               | –                            | –                      | –                                    | –        | –                | –                | –                      | –                          | ✓                     |

!!! note
    Koogは、AIエージェントの作成に最も一般的に使用される機能をサポートしています。
    各プロバイダーのLLMには、Koogが現在サポートしていない追加機能がある場合があります。
    詳細については、[モデル機能](model-capabilities.md)を参照してください。

## プロバイダーとの連携

Koogでは、LLMプロバイダーを2つのレベルで操作できます。

*   特定のプロバイダーと直接対話するための**LLMクライアント**を使用する。
    各クライアントは`LLMClient`インターフェースを実装し、プロバイダーの認証、リクエストのフォーマット、レスポンスのパースを処理します。
    詳細については、[LLMクライアントによるプロンプトの実行](prompt-api.md#running-prompts-with-llm-clients)を参照してください。

*   1つまたは複数のLLMクライアントをラップし、そのライフサイクルを管理し、プロバイダー間のインターフェースを統一する、より高レベルの抽象化である**プロンプトエグゼキューター**を使用する。
    特定のプロバイダーが利用できない場合、オプションで単一のLLMクライアントにフォールバックできます。
    プロンプトエグゼキューターは、障害、リトライ、プロバイダー間の切り替えも処理します。
    独自のエグゼキューターを作成することも、特定のプロバイダー用に事前定義されたプロンプトエグゼキューターを使用することもできます。
    詳細については、[プロンプトエグゼキューターによるプロンプトの実行](prompt-api.md#running-prompts-with-prompt-executors)を参照してください。

## 次のステップ

- 特定のLLMプロバイダーで[エージェントを作成して実行](getting-started.md)する。
- [プロンプト](prompt-api.md)と、[LLMクライアントとプロンプトエグゼキューターの選択方法](prompt-api.md#choosing-between-llm-clients-and-prompt-executors)について詳しく学ぶ。